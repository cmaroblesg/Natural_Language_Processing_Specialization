# Vector Space Models
**DeepLearning.AI**

## Introduction
Vector space models capture semantic meaning and relationships between words. You'll learn how to create word vectors that capture dependencies between words, then visualize their relationships in two dimensions using PCA.

### Learning Objectives
* Covariance matrices
* Dimensionality reduction
* Principal component analysis
* Cosine similarity
* Euclidean distance
* Co-occurrence matrices
* Vector representations
* Vector space models

## Labs:
* [**Lab 01:** Linear Algebra](./labs/C1_W3_lecture_nb_01_linear_algebra.ipynb)
* [**Lab 02:** Manipulating Word Embeddings](./labs/C1_W3_lecture_nb_02_manipulating_word_embeddings.ipynb)
* [**Lab 03:** Another Explanation about PCA](./labs/C1_W3_lecture_nb_03_pca.ipynb)
* [**Assignment**](./labs/)